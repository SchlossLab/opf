---
title: "OPF methods"
author: "Kathryn Iverson"
date: "January 15, 2015"
output: html_document
---

## Overview

The sequence reads from the 20 metagenomes generated by Koren and colleageus (Koren et al., 2012) in their study of the effects of pregnancy on the mother’s microbiome were obtained from MG-RAST.  The reads were pooled and assembled using an iterative assembly. Reads were first assembled with Velvet using a k-mer length of 71 (parameters -exp_cov auto -read_trkg yes -amos_file yes -min_contig_lgth 200 -unused_reads yes) and unused reads were retained. The unused reads were then assembled with k-mer lengths 61, 51 and 41 with the same parameters. The contigs from each of these assemblies were merged with minimus2 (part of AMOS; Sommer et al., 2007) using default parameters.  An average of 54.43% (range 24.23% to 71.78%) of all reads across 20 metagenomes mapped back to the assembled contigs.

The sequence reads from the 18 metagenomes generated by Turnbaugh and colleagues (2009) in their study of the microbiome of lean and obese individuals were obtained from MG-RAST. The reads from all metagenomes were pooled and assembled with Velvet (Zerbino and Birney, 2008) using k 51 (parameters -exp_cov auto -min_contig_lgth 100). The reads from this study were treated as ‘long’ because they were sequenced with 454 pyrosequencing (mean length 216bp, range 9bp to 665bp) whereas the Illumina reads from the pregnancy and mouse studies were treated as ‘short’ (mean length 99bp and 98bp, respectively).  An average of 22.13% (range 4.72% to 35.90%) of all reads across 18 metagenomes mapped back to the assembled contigs.


## Download data

### Downloading raw reads from MG-RAST

First, create a directory to store the data from both the pregnancy and twin studies.

```
mkdir pregnancy_data
mkdir twin_data
```

MG-RAST has an api for downloading data. They provide python scripts to access this api as well as a structured URL. First, download their api from github.

```
git clone https://github.com/MG-RAST/MG-RAST-Tools.git
```
There is a script provided to set up the shell environment and can be run as per their instructions simply by running `.\set_env.sh` inside the tools directory. This script didn't work on all my machines but all it's doing is setting the PYTHONPATH variable and this is easy to do manually. Simply add the absolute path to the MG-RAST-Tools/tools/lib/ directory.

```
cd MG-RAST-Tools
MG_DIR=`pwd`
PYTHONPATH=$PYTHONPATH:$MG_DIR/tools/lib/
```

To download the data from the pregnanacy study, move into the data directory.

```
cd ../pregnancy_data
```

Next, use the MG-RAST tools to download all the raw reads for this dataset. First, get a list of the metagenomes.

```
../MG-RAST-Tools/tools/bin/mg-download.py --project mgp265 --list | sed 's/\t.*$//g' | sed '1d' | uniq > metagenomes.list
```

To download the actual files, use curl. This can be done in parallel if gnu parallel is installed. Otherwise a for-loop will also work.

```
cat metagenomes.list | parallel "curl http://api.metagenomics.anl.gov//download/{}?file=050.1 | tee >(md5sum > {}.md5sum) | gzip > {}.fna.gz"
```

Optional for-loop:
```
for MG in metagenomes.list; do
	curl http://api.metagenomics.anl.gov//download/${MG}?file=050.1 | tee >(md5sum > {}.md5sum)  | gzip > ${MG}.fna.gz
done
```

This will zip the raw fasta files and save the md5sums to validate the download. 


Download the data from the twin study the same way. The only difference is this is MG-RAST project 10 (mgp10)

```
cd ../twin_data
../MG-RAST-Tools/tools/bin/mg-download.py --project mgp10 --list | sed 's/\t.*$//g' | sed '1d' | uniq > metagenomes.list
cat metagenomes.list | parallel "curl http://api.metagenomics.anl.gov//download/{}?file=050.1 | tee >(md5sum > {}.md5sum) | gzip > {}.fna.gz"
```


HMP
de-replicate at 99% BEFORE blast to reduce data size
usearch for all v all
ALL READS mapping for counts


Gene prediction
Genes were predicted from assembled contigs with MetaGeneAnnotator (Noguchi et al., 2008). The predicted genes were separated into two groups: having both a start and stop codon (full length) or fragments with a length greater than 300 nucleotides, including the full length group.

Functional and taxonomic classification
Predicted gene fragments were searched against the eggNOG database (Muller et al., 2010) by BLASTp. Significant hits that had e-values > 10^-5 were grouped into eggNOG categories. Significant hits were defined as any hit that had an e-value <= 10*e-value of the top hit (Qin et al., 2010).

OPF creation and data analysis
Abundance was calculated by number of reads mapping onto predicted genes and fragments,  and normalized for gene length. Mapping was done using bowtie (Langmead et al., 2009). OPFs were created using the mgcluster command in mothur (Schloss et al. 2009). For all analyses the datasets were subsampled to the lowest number of sequences per sample. A Principal component analysis  (PCoA) plot was generated in mothur using the average Yue-Clayton measure of dissimilarity distances (θYC; REF). Plots were generated with R (R Development Core Team, 2012). Similarly a distance matrix was generated from abundance of KEGG categories.
The OPF abundances were transformed into binary data and OPF occurrences within and between groups of samples inside each dataset were analyzed with R.  For the mice data, we combined the 16S and OPF data using correlation analysis and these results are summarized in a heatmap showing the 20 OTUs that had significantly different abundance during the early and late periods and the OPFs correlating with these.








=======================

For the mice study the primer sequences were removed from raw reads using SeqPrep (available at https://github.com/jstjohn/seqPrep).

```
seqPrep
```

The reads were normalized by median using khmer with k-mer length of 20, count of 20, hash size of 1e9 and 4 hashes (parameters -k 20 -C 20 -x 1e9 -N 4) (Brown et al., 2012). This excluded from assembly any read that had a median k-mer of length 20 that had previously been encountered at least 20 times. This data reduction step removed redundant reads unlikely to add any more information to the assembly. The excluded reads were saved for downstream analysis. The remaining reads were filtered by abundance removing any low abundance (<5) and unique k-mers that are unlikely to assemble into larger contigs

```
khmer
```

Obesity study dataset.  

The sequence reads from the 18 metagenomes generated by Turnbaugh and colleagues (2009) in their study of the microbiome of lean and obese individuals were obtained from MG-RAST.

```
wget
```

The reads from all metagenomes were pooled and assembled with Velvet (Zerbino and Birney, 2008) using k 51 (parameters -exp_cov auto -min_contig_lgth 100). The reads from this study were treated as ‘long’ because they were sequenced with 454 pyrosequencing (mean length 216bp, range 9bp to 665bp) whereas the Illumina reads from the pregnancy and mouse studies were treated as ‘short’ (mean length 99bp and 98bp, respectively).  An average of 22.13% (range 4.72% to 35.90%) of all reads across 18 metagenomes mapped back to the assembled contigs.

Pregnancy study dataset.  

The sequence reads from the 20 metagenomes generated by Koren and colleageus (Koren et al., 2012) in their study of the effects of pregnancy on the mother’s microbiome were obtained from MG-RAST.  The reads were pooled and assembled using an iterative assembly. Reads were first assembled with Velvet using a k-mer length of 71 (parameters -exp_cov auto -read_trkg yes -amos_file yes -min_contig_lgth 200 -unused_reads yes) and unused reads were retained. The unused reads were then assembled with k-mer lengths 61, 51 and 41 with the same parameters. The contigs from each of these assemblies were merged with minimus2 (part of AMOS; Sommer et al., 2007) using default parameters.  An average of 54.43% (range 24.23% to 71.78%) of all reads across 20 metagenomes mapped back to the assembled contigs.

Mouse gut microbiome stability dataset.  

Using the Illumina HiSeq and standard methods (http://hmpdacc.org/doc/HMP_MOP_Version12_0_072910.pdf), we generated 48 metagenomes from samples for which we previously obtained 16S rRNA gene sequence data (Schloss et al., 2012).  The sequencing was performed at the Baylor College of Medicine (Houston, TX).  All reads from the mice study were pooled into two groups corresponding to early and late samples. After normalization 15% of the late reads (false positive rate of 0.000) and 17% of the early (false positive rate of 0.258) were retained for assembly. The unused reads were set aside and used in downstream analysis.  The retained reads were assembled twice with Velvet using k 31 and k 35 (parameters -exp_cov auto -cov_cutoff 0 -scaffolding no). Both assemblies were merged with minimus2 using default parameters.  An average of 84% (range XX.XX% to XX.XX%) of all reads across 48 metagenomes mapped back to the assembled contigs.

Gene prediction and classification.  

Genes were predicted from assembled contigs with MetaGeneAnnotator (Noguchi et al., 2008). The predicted genes were filtered to only include predicted genes and fragments with a length greater than 300 nucleotides.  Predicted genes and fragments were translated and searched against the KEGG database (Kanehisa et al., 2012) by BLASTp. Significant hits that had e-values less than 10^-5 were grouped into KEGG modules.  Significant hits were defined as any hit that had an e-value less than or equal to 10 times the e-value of the top hit (Qin et al., 2010).

OPF creation and data analysis.  

Abundance was calculated by number of reads mapping onto predicted gene fragments and normalized for gene length. Mapping was done using Bowtie (Langmead et al., 2009) for the mice and pregnancy reads and BWA-SW (Li and Durbin, 2010) for the obesity reads.  OPFs were created from the predicted genes and fragments using the mgcluster command in mothur (Schloss et al., 2009).  To minimize the effects of uneven sampling, within a dataset each sample was rarefied to the lowest number of sequences per sample.  Principal component analysis (PCoA) plots were generated in mothur using the average Yue-Clayton measure of dissimilarity distances (θYC; Yue and Clayton, 2005) or weighted or unweighted Unifrac distances (Lozupone and Knight, 2005).  Statistical testing was done within the R environment (R Development Core Team, 2012) and mothur.




Data processing
Quality assurance, normalization
SeqPrep (available at https://github.com/jstjohn/seqPrep) was used to remove primer sequences from reads.  Reads were normalized by median using khmer with k-mer length of 20, count of 20, hash size 1e9 and 4 hashes (parameters -k 20 -C 20 -x 1e9 -N 4) (Brown et al. 2012). This excluded from assembly any read that had a median k-mer of length 20 that had previously been encountered at least 20 times. This data reduction step removed redundant reads unlikely to add any more information to the assembly. The excluded reads were saved for downstream analysis. The remaining reads were filtered by abundance using filter-abund.py. This removed any low abundance and unique k-mers that are unlikely to assemble into larger contigs.

Assembly
To demonstrate robustness to assembly methods the normalized reads were assembled using two assembly methods.

Mice and twin
Reads were assembled twice with velvet (Zerbino and Birney, 2008) using k 31 and k 35 (parameters -exp_cov auto -cov_cutoff 0 -scaffolding no). Both assemblies were merged with minimus2,part of AMOS (Sommer et al., 2007), using default parameters.

Pregnancy
Reads from the pregnancy data were assembled using an iterative assembly. Reads were assembled with velvet using k 71 and unused reads were retained. These unused reads were then assembled with k 61, k 51 and k 41 (parameters -exp_cov auto -read_trkg yes -amos_file yes -min_contig_lgth 200 -unused_reads yes). The contigs from each of these assemblies were merged with minimus2 using default parameters.


